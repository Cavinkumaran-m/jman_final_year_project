{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MSSQL connection details\n",
    "# HOME MACHINE = DESKTOP-CMTGLLQ\n",
    "# CORP MACHINE = JM-DKT-033\n",
    "connection_string = 'DRIVER={SQL Server};SERVER=JM-DKT-033;DATABASE=JLEARN;trusted_connection=YES'\n",
    "\n",
    "# Connect to the database\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for the Medallion architecture\n",
    "base_dir = \"warehouse\"\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "def create_folders():\n",
    "    layers = ['raw', 'prep', 'mart']\n",
    "    for directory in layers:\n",
    "        if not os.path.exists(base_dir + \"/\" + directory):\n",
    "            os.makedirs(base_dir + \"/\" + directory)\n",
    "\n",
    "create_folders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PREPARING DATABASE\n",
    "# def clean_db():\n",
    "#     schemas = ['raw','prep','mart']\n",
    "#     tables = ['user_courses','users','courses']\n",
    "#     def create_schema(schema):\n",
    "#         query = f\"select schema_id('{schema}');\"\n",
    "#         cursor.execute(query)\n",
    "#         res = tuple(cursor.fetchall()[0])[0]\n",
    "#         if(res == None):\n",
    "#             query = f\"create schema {schema};\"\n",
    "#             cursor.execute(query)\n",
    "#             print(f\"{schema} schema created\")\n",
    "#             conn.commit()\n",
    "\n",
    "#     def drop_tables(schema, table):\n",
    "#         query = f\"DROP TABLE IF EXISTS {schema}.{table};\"\n",
    "#         cursor.execute(query)\n",
    "#         conn.commit()\n",
    "\n",
    "#     def create_users_table(schema):\n",
    "#         query = f\"\"\"CREATE TABLE {schema}.users (\n",
    "#             UserID       INT            PRIMARY KEY,\n",
    "#             UserName     NVARCHAR(100),\n",
    "#             FullName     NVARCHAR(100),\n",
    "#             Email        NVARCHAR(255) UNIQUE,\n",
    "#             PasswordHash NVARCHAR(255),\n",
    "#             Role         NVARCHAR(50)   DEFAULT 'employee',\n",
    "#             RegisteredAt DATETIME       DEFAULT GETDATE()\n",
    "#         )\"\"\"\n",
    "#         cursor.execute(query)\n",
    "#         conn.commit()\n",
    "\n",
    "#     def create_courses_table(schema):\n",
    "#         query = f\"\"\"CREATE TABLE {schema}.courses (\n",
    "#             course_id           INT            PRIMARY KEY,\n",
    "#             course_title        NVARCHAR(100),\n",
    "#             num_subscribers     INT,\n",
    "#             num_reviews         SMALLINT,\n",
    "#             num_lectures        SMALLINT,\n",
    "#             level               NVARCHAR(50),\n",
    "#             content_duration    FLOAT,\n",
    "#             published_timestamp NVARCHAR(50),\n",
    "#             subject             NVARCHAR(50)\n",
    "#         )\"\"\"\n",
    "#         cursor.execute(query)\n",
    "#         conn.commit()\n",
    "\n",
    "#     def create_user_courses_table(schema):\n",
    "#         query = f\"\"\"CREATE TABLE {schema}.user_courses (\n",
    "#             user_course_id INT       PRIMARY KEY,\n",
    "#             user_id        INT,\n",
    "#             course_id      INT,\n",
    "#             status         VARCHAR(50),\n",
    "#             progress       DECIMAL(5, 2) DEFAULT 0.00,\n",
    "#             enrolled_at    DATETIME      DEFAULT GETDATE(),\n",
    "#             completed_at   DATETIME,\n",
    "#             score          DECIMAL(5, 2),\n",
    "#             CONSTRAINT FK_user_courses_users FOREIGN KEY (user_id) REFERENCES raw.users(UserID),\n",
    "#             CONSTRAINT FK_user_courses_courses FOREIGN KEY (course_id) REFERENCES raw.courses(course_id)\n",
    "#         )\"\"\"\n",
    "#         cursor.execute(query)\n",
    "#         conn.commit()\n",
    "\n",
    "#     for schema in schemas:\n",
    "#         create_schema(schema)\n",
    "#         for table in tables:\n",
    "#             drop_tables(schema, table)\n",
    "\n",
    "#     create_users_table('raw')\n",
    "#     create_courses_table('raw')\n",
    "#     create_user_courses_table('raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data using pyodbc and convert to pandas DataFrame\n",
    "def fetch_data(query, conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    data = cursor.fetchall()\n",
    "    df = pd.DataFrame([tuple(row) for row in data], columns=columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to save data to both CSV and SQL Server\n",
    "\n",
    "def save_data(df, table_name, stage):\n",
    "\n",
    "    # Save to CSV\n",
    "    if \"PasswordHash\" in df.columns:\n",
    "        df = df.drop(\"PasswordHash\", axis=1) \n",
    "        \n",
    "    file_path = os.path.join(base_dir + \"\\\\\" +stage, f'{table_name}.csv')\n",
    "    # {datetime.now().strftime(\"%Y%m%d_%H%M%S\")}\n",
    "    # print(file_path)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "    # Save to SQL Server\n",
    "\n",
    "    # df = df.applymap(lambda x: x.strftime('%Y-%m-%d %H:%M:%S') if isinstance(x, pd.Timestamp) else x)\n",
    "    # df = df.applymap(lambda x: float(x) if isinstance(x, Decimal) else x)\n",
    "    # df = df.applymap(lambda x: None if isinstance(x, pd.notna) else x)\n",
    "    # df = df.applymap(lambda x: None if (isinstance(x, Decimal) and (x.is_nan() or x == Decimal('NaN'))) else float(x) if isinstance(x, Decimal) else x)\n",
    "    # df = df.replace(\"'\",\"\", regex=True)\n",
    "\n",
    "    \n",
    "    # conn_str = f\"INSERT INTO {schema}.{table_name} ({', '.join(df.columns)}) VALUES \"\n",
    "    # values = ', '.join([str(tuple(row)) for row in df.values])\n",
    "    # query = conn_str + values\n",
    "    # print(values)\n",
    "    # with conn.cursor() as cursor:\n",
    "    #     cursor.execute(query)\n",
    "    #     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T FORGET TO CREATE RESPECTIVE TABLES IN EACH SCHEMA\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1. RAW Layer: Raw data ingestion from tables\n",
    "# ----------------------------------------------\n",
    "# Ingest raw data from SQL Server\n",
    "def raw_ingestion():\n",
    "    user_query = \"SELECT * FROM users\"\n",
    "    course_query = \"SELECT * FROM courses\"\n",
    "    user_courses_query = \"SELECT * FROM user_courses\"\n",
    "    \n",
    "    # Fetching raw data\n",
    "    users_df = fetch_data(user_query, conn)\n",
    "    courses_df = fetch_data(course_query, conn)\n",
    "    user_courses_df = fetch_data(user_courses_query, conn)\n",
    "    \n",
    "    # Save raw data\n",
    "    save_data(users_df, 'users','raw')\n",
    "    save_data(courses_df, 'courses', 'raw')\n",
    "    save_data(user_courses_df, 'user_courses', 'raw')\n",
    "\n",
    "# clean_db()\n",
    "raw_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# 2. PREP Layer: Cleansing and Enrichment\n",
    "# ----------------------------------------------\n",
    "def prep_transformation():\n",
    "    # Clean and join the data (Enrichment)\n",
    "    raw_courses_df = pd.read_csv(\"warehouse/raw/courses.csv\")\n",
    "    raw_user_courses_df = pd.read_csv(\"warehouse/raw/user_courses.csv\")\n",
    "    raw_users_df = pd.read_csv(\"warehouse/raw/users.csv\")\n",
    "    \n",
    "\n",
    "    raw_users_df = raw_users_df.dropna()\n",
    "    raw_courses_df = raw_courses_df.dropna()\n",
    "    raw_user_courses_df = raw_user_courses_df.dropna()\n",
    "\n",
    "    save_data(raw_users_df, 'users', 'prep')\n",
    "    save_data(raw_courses_df, 'courses', 'prep')\n",
    "    save_data(raw_user_courses_df, 'user_courses', 'prep')\n",
    "    \n",
    "\n",
    "prep_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# 3. MART Layer: Aggregation and Analysis\n",
    "# ----------------------------------------------\n",
    "def mart_transformation():\n",
    "    # Aggregate course completion statistics\n",
    "    # gold_query = \"\"\"\n",
    "    # SELECT c.course_title, COUNT(uc.user_course_id) as num_users, AVG(uc.progress) as avg_progress\n",
    "    # FROM user_courses uc\n",
    "    # JOIN courses c ON uc.course_id = c.course_id\n",
    "    # WHERE uc.progress = 100\n",
    "    # GROUP BY c.course_title\n",
    "    # \"\"\"\n",
    "\n",
    "    prep_courses_df = pd.read_csv(\"warehouse/prep/courses.csv\")\n",
    "    prep_user_courses_df = pd.read_csv(\"warehouse/prep/user_courses.csv\")\n",
    "    prep_users_df = pd.read_csv(\"warehouse/prep/users.csv\")\n",
    "\n",
    "    merged_df = pd.merge(prep_users_df, prep_user_courses_df, left_on='UserID', right_on='user_id', how='inner')\n",
    "\n",
    "    # Step 2: Merge the result with courses on course_id\n",
    "    final_merged_df = pd.merge(merged_df, prep_courses_df, left_on='course_id', right_on='course_id', how='inner')\n",
    "    final_merged_df = final_merged_df.drop(\"user_id\", axis=1)\n",
    "    # Save aggregated data\n",
    "    save_data(final_merged_df, 'report', 'mart')\n",
    "\n",
    "mart_transformation()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
